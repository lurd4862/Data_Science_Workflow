---
title: "Data Science Workflow"
author: "stefan"
date: "3/26/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Why it matters

When working with recurring clients and projects together with tight deadlines it is easy to cut corners or forget good practice.

Here are the top reasons why a data science workflow is vital:  

- Work is well documented  
- Folders and files logically are structured  
- Projects remain version controlled  
- Data output is tracked  
- Logical seperation of scripts make productizing easy  
- Good naming conventions make tracking of the project flow easy  
- Returning to the same methodology is met with less panic  
- Changing the project structure becomes more difficult the longer you wait

### Projects structure

Your project should have at least 2 main housing folders;  

- A git repository for maintaining code  
- A local folder on a shared drive containing data and outputs  

#### Git repository

The git repository is essential for effective collaboration, tracking and version control.

The git repository will usually comprise of the following folders;  

(@) static

A folder for keeping sub folders for images/references/material used in markdowns and client rendered documents

(@) *language*_scripts e.g __R_scripts__

- Each script should contain a number/letter (or both) prefix to indicate a logical order of execution  
- Similar to code normalization it is important that each script should achieve a very specific task. If a script achieves more than one result we should consider splitting the script up  
- Functions should be sourced from an appropriately named script  


(@) about

This folder should contain flowcharts, package versions and a description of what the code does.  

#### Local folder

Should contain folders for;  

(@) plot_output

All plots generated by scripts should be saved to appropriate sub folders in here.  

(@) presentations

All client presentation versions should be stored here

(@) data

- raw_data - all data recieved directly from the client  
- molded_data - all data that we have engineered in some way to some purpose  

(@) objects

Code execution will often require some time. For this reason and for reproducibility it is important that intermediate results be saved. Save all intermediate objects used in scripts here.

## Workflow



![](static/DU15n6_WAAIW8KC.jpg)

